{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from PIL import Image, ImageTk\n",
    "from typing import Tuple\n",
    "from tkinter import *\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656, 368, 3)\n",
      "(0, 0, 79, 82)\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "%reload_ext main\n",
    "\n",
    "scale = 1\n",
    "stride = 4\n",
    "margin = 40\n",
    "\n",
    "video = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "\n",
    "_, first_frame = video.read()\n",
    "first_frame = preprocess_frame(first_frame, scale=scale)\n",
    "while True:\n",
    "    selected_box = SelectBoxWindow.show_and_get_box(first_frame)\n",
    "    if selected_box[-1] != 0 and selected_box[-2] != 0:\n",
    "        break\n",
    "print(selected_box)\n",
    "\n",
    "tracker = ObjectTracker(first_frame, selected_box,\n",
    "                        stride=stride, margin=margin, \n",
    "                        coords_mem_size=3, \n",
    "                        sigma=1.5, \n",
    "                        first_last_ratio=[0.6, 0.4], \n",
    "                        weights_coef=2.0)\n",
    "show_tracking_animation(video, tracker, scale=scale, thickness=3, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pytictoc\n",
    "from main import *\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple\n",
    "from skimage import morphology\n",
    "%reload_ext main\n",
    "\n",
    "timer = pytictoc.TicToc()\n",
    "\n",
    "scale = 1\n",
    "stride = 4\n",
    "margin = 40\n",
    "\n",
    "video = cv2.VideoCapture(\"videos/basketball_1.mp4\")\n",
    "\n",
    "\n",
    "def get_keypoints(img: np.ndarray, nfeatures=40, nOctaveLayers: int = 3, sigma: float = 1.5):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, sigma=sigma)\n",
    "    kp, dsc = sift.detectAndCompute(gray, None)\n",
    "    return kp, dsc, gray\n",
    "\n",
    "\n",
    "def center_of_mass_match(img1: np.ndarray, img2: np.ndarray, cv2_norm: int = cv2.NORM_L1, nfeatures=40, nOctaveLayers: int = 3, sigma: float = 1.5, def_yx=(-1, -1)):\n",
    "    try:\n",
    "        kp1, dsc1, gray1 = get_keypoints(img1, nfeatures, nOctaveLayers, sigma)\n",
    "        kp2, dsc2, gray2 = get_keypoints(img2, nfeatures, nOctaveLayers, sigma)\n",
    "        bf = cv2.BFMatcher(cv2_norm, crossCheck=True)\n",
    "        matches = bf.match(dsc1, dsc2)\n",
    "        indexes = np.asarray(\n",
    "            [kp2[m.trainIdx].pt for m in matches], dtype='int')\n",
    "        if len(indexes):\n",
    "            x, y = np.mean(indexes, axis=0, dtype='int')\n",
    "            return y, x\n",
    "    except:\n",
    "        pass\n",
    "    # Match not found\n",
    "    return def_yx\n",
    "\n",
    "\n",
    "def connect_images(frame: np.ndarray, track_window: Tuple[int, int], img1: np.ndarray, img2: np.ndarray, cv2_norm: int = cv2.NORM_L1, nfeatures=40, nOctaveLayers: int = 3, sigma: float = 1.5):\n",
    "    # , nfeatures, nOctaveLayers, sigma)\n",
    "    kp1, dsc1, gray1 = get_keypoints(img1)\n",
    "    # , nfeatures, nOctaveLayers, sigma)\n",
    "    kp2, dsc2, gray2 = get_keypoints(img2)\n",
    "    bf = cv2.BFMatcher(cv2_norm, crossCheck=True)\n",
    "    matches = bf.match(dsc1, dsc2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches, img2, flags=2)\n",
    "    plt.imshow(img3)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    indexes = np.asarray(\n",
    "        [kp2[m.trainIdx].pt for m in matches], dtype='int')[..., ::-1]\n",
    "\n",
    "    indexes[..., 0] += track_window[0] - (img2.shape[0] - img1.shape[0]) // 2\n",
    "    indexes[..., 1] += track_window[1] - (img2.shape[1] - img1.shape[1]) // 2\n",
    "\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    # img4 = np.zeros(frame.shape[:2])\n",
    "    img4 = np.copy(frame)\n",
    "    dst = np.zeros(frame.shape[:2])\n",
    "\n",
    "    disk = morphology.disk(25)[..., np.newaxis] * 255.0\n",
    "    disk = np.repeat(disk, 3, axis=-1)\n",
    "    dy, dx = np.asarray(disk.shape[:2]) // 2\n",
    "\n",
    "    for index in indexes:\n",
    "        y, x = index\n",
    "        # img4[y-dy:y+dy+1, x-dx:x+dx+1] = disk\n",
    "        # dst[y-dy:y+dy+1, x-dx:x+dx+1] += disk[..., 0]\n",
    "        dst[y, x] = 1\n",
    "\n",
    "    dst /= np.max(dst)\n",
    "    _, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "    # plt.figure(figsize=(24, 16))\n",
    "    # plt.imshow(dst, 'gray')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return track_window\n",
    "    plt.figure(figsize=(24, 16))\n",
    "    plt.imshow(img4)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "_, img = video.read()\n",
    "margin = 20\n",
    "nfeatures = 5\n",
    "nOctaveLayers = 3\n",
    "sigma = 1.5\n",
    "\n",
    "\n",
    "y, x, w, h = (209, 760, 28, 29)\n",
    "# y, x, w, h = (324, 197, 38, 36)\n",
    "# y, x, w, h = (363, 836, 108, 246)\n",
    "height, width, _ = img.shape\n",
    "\n",
    "plt.imshow(img[y:y+h, x:x+w])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "mem_len = 3\n",
    "mem = collections.deque([(y, x) for _ in range(mem_len)], maxlen=mem_len)\n",
    "weights = np.arange(1, mem_len + 1) ** 3\n",
    "weights = weights / np.sum(weights)\n",
    "\n",
    "for i in range(600):\n",
    "    ret, nimg = video.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    part1 = img[y:y+h, x:x+w]\n",
    "    part2 = nimg[y-margin:y+h+margin, x-margin:x+w+margin]\n",
    "\n",
    "    cy, cx = center_of_mass_match(\n",
    "        part1, part2, nfeatures=nfeatures, nOctaveLayers=nOctaveLayers, sigma=sigma, def_yx=mem[-1])\n",
    "\n",
    "    print(y, x, cy, cx)\n",
    "    _y, _x = cy + y - part2.shape[0] // 2, cx + x - part2.shape[1] // 2\n",
    "    #ny, nx = min(max(0, _y), height - h), min(max(0, _x), width - w)\n",
    "    ny, nx = _y, _x\n",
    "    mem.append((ny, nx))\n",
    "\n",
    "    avg_y, avg_x = np.average(mem, axis=0, weights=weights)\n",
    "    y, x = int(avg_y), int(avg_x)\n",
    "\n",
    "    \n",
    "    frame = cv2.rectangle(np.copy(nimg), (x, y),\n",
    "                          (x+w, y+h), (0, 0, 255), thickness=3)\n",
    "    if False:\n",
    "        frame[y, x] = (255, 255, 255)\n",
    "        plt.figure(figsize=(24, 16))\n",
    "        plt.imshow(frame)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        cv2.imshow('frame', frame)\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    img = nimg\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "video.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a48581e28d45680af6ef7ae6138d429f6e20aecedaea2d4b58ab16969b43f7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
